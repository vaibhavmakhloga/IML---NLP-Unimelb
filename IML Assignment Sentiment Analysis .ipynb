{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8c5b091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# ignore future warnings \n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "443de3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('TRAIN.csv')\n",
    "validation_data = pd.read_csv('VALIDATION.csv')\n",
    "test_data = pd.read_csv('TEST_NO_LABELS.csv')\n",
    "\n",
    "# Load the TF-IDF features for baselines \n",
    "tfidf_train = pd.read_csv('TFIDF_TRAIN.csv')\n",
    "tfidf_validation = pd.read_csv('TFIDF_VALIDATION.csv')\n",
    "\n",
    "\n",
    "y_train = train_data['rating']\n",
    "y_test = validation_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "91e3758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^A-Za-z]', ' ', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and perform lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "    \n",
    "    # Join the words back into a clean text\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Function to create a pipeline for data preprocessing and TF-IDF with a specified classifier\n",
    "def create_pipeline(classifier):\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=2000)),  # TF-IDF vectorization\n",
    "        ('classifier', classifier)  # Classifier (Logistic Regression, Multinomial Naive Bayes)\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "91d97506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test a model on a specific dataset\n",
    "def test_model(model, X, y):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    class_report = classification_report(y, y_pred)\n",
    "    print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "992c255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "train_data['review-text-cleaned'] = train_data['review-text-cleaned'].apply(clean_text)\n",
    "validation_data['review-text-cleaned'] = validation_data['review-text-cleaned'].apply(clean_text)\n",
    "\n",
    "# Create pipelines with different classifiers\n",
    "logistic_regression_pipeline = create_pipeline(LogisticRegression())\n",
    "naive_bayes_pipeline = create_pipeline(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3cd6dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to model the data\n",
    "def model_data(train_data, validation_data, pipeline, classifier_name):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train = train_data['review-text-cleaned']\n",
    "    y_train = train_data['rating']\n",
    "    \n",
    "    X_validation = validation_data['review-text-cleaned']\n",
    "    y_validation = validation_data['rating']\n",
    "\n",
    "    # Fit the model with the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model on the validation data\n",
    "    print(f\"Testing on {classifier_name}:\\n\")\n",
    "    test_model(pipeline, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c47a4d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Logistic Regression (Whole Data):\n",
      "\n",
      "Accuracy: 0.9156363636363636\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.86      0.84      1462\n",
      "           1       0.95      0.94      0.94      4038\n",
      "\n",
      "    accuracy                           0.92      5500\n",
      "   macro avg       0.89      0.90      0.89      5500\n",
      "weighted avg       0.92      0.92      0.92      5500\n",
      "\n",
      "Testing on Multinomial Naive Bayes (Whole Data):\n",
      "\n",
      "Accuracy: 0.893090909090909\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.70      0.78      1462\n",
      "           1       0.90      0.96      0.93      4038\n",
      "\n",
      "    accuracy                           0.89      5500\n",
      "   macro avg       0.88      0.83      0.85      5500\n",
      "weighted avg       0.89      0.89      0.89      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model the data on the whole dataset using different classifiers\n",
    "model_data(train_data, validation_data, logistic_regression_pipeline, \"Logistic Regression (Whole Data)\")\n",
    "model_data(train_data, validation_data, naive_bayes_pipeline, \"Multinomial Naive Bayes (Whole Data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "067f1849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Logistic Regression (Female):\n",
      "\n",
      "Accuracy: 0.9291917167668671\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.86      0.86       392\n",
      "           1       0.95      0.95      0.95      1105\n",
      "\n",
      "    accuracy                           0.93      1497\n",
      "   macro avg       0.91      0.91      0.91      1497\n",
      "weighted avg       0.93      0.93      0.93      1497\n",
      "\n",
      "Testing on Logistic Regression(Male):\n",
      "\n",
      "Accuracy: 0.923828125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.86      0.86       983\n",
      "           1       0.95      0.95      0.95      2601\n",
      "\n",
      "    accuracy                           0.92      3584\n",
      "   macro avg       0.90      0.90      0.90      3584\n",
      "weighted avg       0.92      0.92      0.92      3584\n",
      "\n",
      "Testing on Logistic Regression(Unknown):\n",
      "\n",
      "Accuracy: 0.7971360381861575\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.82      0.63        87\n",
      "           1       0.94      0.79      0.86       332\n",
      "\n",
      "    accuracy                           0.80       419\n",
      "   macro avg       0.72      0.80      0.74       419\n",
      "weighted avg       0.85      0.80      0.81       419\n",
      "\n",
      "Testing on Multinomial Naive Bayes (Female):\n",
      "\n",
      "Accuracy: 0.9004676018704075\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.76      0.80       392\n",
      "           1       0.92      0.95      0.93      1105\n",
      "\n",
      "    accuracy                           0.90      1497\n",
      "   macro avg       0.88      0.85      0.87      1497\n",
      "weighted avg       0.90      0.90      0.90      1497\n",
      "\n",
      "Testing on Multinomial Naive Bayes (Male):\n",
      "\n",
      "Accuracy: 0.8956473214285714\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.72      0.79       983\n",
      "           1       0.90      0.96      0.93      2601\n",
      "\n",
      "    accuracy                           0.90      3584\n",
      "   macro avg       0.89      0.84      0.86      3584\n",
      "weighted avg       0.89      0.90      0.89      3584\n",
      "\n",
      "Testing on Multinomial Naive Bayes (Unknown):\n",
      "\n",
      "Accuracy: 0.8448687350835322\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.32      0.46        87\n",
      "           1       0.85      0.98      0.91       332\n",
      "\n",
      "    accuracy                           0.84       419\n",
      "   macro avg       0.84      0.65      0.69       419\n",
      "weighted avg       0.84      0.84      0.82       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide validation data based on gender\n",
    "female_validation_data = validation_data[validation_data['dr_id_gender'] == 0]\n",
    "male_validation_data = validation_data[validation_data['dr_id_gender'] == 1]\n",
    "unknown_gender_validation_data = validation_data[validation_data['dr_id_gender'] == 2]\n",
    "\n",
    "# Model the data for each gender category separately using different classifiers\n",
    "model_data(train_data, female_validation_data, logistic_regression_pipeline, \"Logistic Regression (Female)\")\n",
    "model_data(train_data, male_validation_data, logistic_regression_pipeline, \"Logistic Regression(Male)\")\n",
    "model_data(train_data, unknown_gender_validation_data, logistic_regression_pipeline, \"Logistic Regression(Unknown)\")\n",
    "\n",
    "model_data(train_data, female_validation_data, naive_bayes_pipeline, \"Multinomial Naive Bayes (Female)\")\n",
    "model_data(train_data, male_validation_data, naive_bayes_pipeline, \"Multinomial Naive Bayes (Male)\")\n",
    "model_data(train_data, unknown_gender_validation_data, naive_bayes_pipeline, \"Multinomial Naive Bayes (Unknown)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "fc63a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for calculating the baselines using OneR and ZeroR\n",
    "def baselines(xtrain,ytrain,xtest,ytest):\n",
    "    \n",
    "    OneR_Acc_1 = []\n",
    "    ZeroR_Acc_1 = []\n",
    "    \n",
    "    # One-R model\n",
    "    OneR_Model = DummyClassifier(strategy=\"prior\")\n",
    "    OneR_Model.fit(xtrain, ytrain)\n",
    "    OneR_Predictions = OneR_Model.predict(xtest)\n",
    "    OneR_Acc = accuracy_score(ytest, OneR_Predictions)\n",
    "    OneR_Acc_1.append(OneR_Acc)\n",
    "    \n",
    "    print(\"Accuracy of One-R:\", np.mean(OneR_Acc_1).round(2))\n",
    "    class_report = classification_report(ytest, OneR_Predictions)\n",
    "    print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ebee1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One-R: 0.73\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines(tfidf_train,y_train,tfidf_validation,validation_data.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "753debe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One-R: 0.73\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       983\n",
      "           1       0.73      1.00      0.84      2601\n",
      "\n",
      "    accuracy                           0.73      3584\n",
      "   macro avg       0.36      0.50      0.42      3584\n",
      "weighted avg       0.53      0.73      0.61      3584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines(tfidf_train,y_train,tfidf_validation_male,validation_male_df.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d00924ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One-R: 0.74\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       392\n",
      "           1       0.74      1.00      0.85      1105\n",
      "\n",
      "    accuracy                           0.74      1497\n",
      "   macro avg       0.37      0.50      0.42      1497\n",
      "weighted avg       0.54      0.74      0.63      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines(tfidf_train,y_train,tfidf_validation_female,validation_female_df.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6e59d19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of One-R: 0.79\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        87\n",
      "           1       0.79      1.00      0.88       332\n",
      "\n",
      "    accuracy                           0.79       419\n",
      "   macro avg       0.40      0.50      0.44       419\n",
      "weighted avg       0.63      0.79      0.70       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baselines(tfidf_train,y_train,tfidf_validation_unknown,validation_unknown_df.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d9a813b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on the Test data. \n",
    "\n",
    "# Clean the text data\n",
    "train_data['review-text-cleaned'] = train_data['review-text-cleaned'].apply(clean_text)\n",
    "test_data['review-text-cleaned'] = test_data['review-text-cleaned'].apply(clean_text)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)  # TF-IDF vectorization\n",
    "\n",
    "# Transform the text data into TF-IDF features\n",
    "X_train = tfidf_vectorizer.fit_transform(train_data['review-text-cleaned'])\n",
    "y_train = train_data['rating']\n",
    "\n",
    "X_test = tfidf_vectorizer.transform(test_data['review-text-cleaned'])\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ba3a9fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1, -1,  1])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "65d4f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__\n",
    "\n",
    "def get_version(pkg):\n",
    "    try:\n",
    "        return pkg_resources.get_distribution(pkg).version\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        return None\n",
    "\n",
    "imports = list(get_imports())\n",
    "packages = [pkg for pkg in imports if pkg != 'builtins']\n",
    "\n",
    "versions = {pkg: get_version(pkg) for pkg in packages}\n",
    "\n",
    "# Save the versions to a text file\n",
    "with open('README3.txt', 'w') as file:\n",
    "    for pkg, version in versions.items():\n",
    "        file.write(f\"{pkg}: {version}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "54c01867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "sklearn_version = re.__version__\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn_version}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
